{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model\n",
    "import random\n",
    "# from planar_utils import plot_decision_boundary, sigmoid, load_planar_dataset, load_extra_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "outputs": [],
   "source": [
    "a=[]\n",
    "b=[]\n",
    "for i in range(500):\n",
    "    a.append(random.randint(0,1))\n",
    "    b.append(random.randint(0,1))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "outputs": [],
   "source": [
    "#a = np.array(a)\n",
    "#a = a.reshape(-1,1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "outputs": [],
   "source": [
    "#b = np.array(b)\n",
    "#b = b.reshape(-1,1)\n",
    "\n",
    "z = list(zip(a,b))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "outputs": [],
   "source": [
    "c=[]\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "for i in range(len(z)):\n",
    "    if z[i][0] ==z[i][1]:\n",
    "        c.append(0)\n",
    "    else:\n",
    "        c.append(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "outputs": [],
   "source": [
    "#value_prediction  = list(zip(a,b,c))\n",
    "#print(value_prediction)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "outputs": [],
   "source": [
    "a = np.array(a)\n",
    "b = np.array(b)\n",
    "c = np.array(c)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "outputs": [],
   "source": [
    "d  = np.vstack([a,b])\n",
    "X =d\n",
    "Y = c.reshape(1,500)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[[0 1 1 1 0 0 0 0 1 0 0 1 1 0 0 1 1 1 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0\n  1 1 0 0 0 1 1 1 0 1 0 1 1 0 0 1 0 1 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0\n  1 1 1 1 1 1 0 0 1 1 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0\n  0 1 1 0 0 1 0 0 0 1 1 0 1 1 1 1 0 1 1 1 0 1 0 0 1 0 1 1 1 1 0 0 1 1 0 1\n  0 1 1 0 0 1 0 1 1 0 0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 0 0 0 1 0 0 1 1 1 1\n  0 1 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 0\n  0 1 0 0 1 1 1 0 0 1 1 1 0 1 1 1 0 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0 1 0 1 0\n  1 1 1 1 0 0 1 1 1 0 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 0 0 0 0 1 1 0 1 0 1 1\n  1 0 0 0 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 0 0 0 1 0 0 0 1 1 1 1 0 1 1 0 1 1\n  1 0 1 1 1 1 1 0 0 1 1 0 1 0 1 0 0 1 1 1 1 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0\n  0 1 0 0 0 1 0 1 0 1 1 1 0 0 1 0 0 0 0 1 0 1 0 0 1 1 1 1 0 0 1 0 0 1 0 0\n  1 0 0 0 1 0 1 1 0 0 0 0 1 0 1 0 1 1 1 1 1 0 0 1 1 1 0 0 0 1 1 0 0 0 1 0\n  1 0 1 0 0 1 1 1 1 1 1 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 0 1 0 1 1 1 1 0\n  0 1 1 0 0 0 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0]\n [1 1 0 0 0 1 0 0 0 1 1 1 1 0 1 1 0 1 0 1 0 0 0 0 1 1 1 0 1 1 1 1 1 0 0 0\n  1 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0 1 1 0 1 1\n  0 1 1 0 0 0 1 1 0 1 0 0 1 1 0 0 1 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 0 0 0 1\n  1 0 1 1 0 0 0 0 1 0 0 1 0 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 0 1 0\n  1 0 1 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 0 0 0 0 0\n  1 1 1 0 0 1 0 0 1 0 1 0 0 0 1 1 1 0 0 1 0 0 0 0 1 0 1 1 0 1 1 1 1 1 1 1\n  1 0 1 1 0 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 0 1 0 1 1 1 0 1 0 1 0 1 1 0 0 0\n  0 0 0 0 1 0 1 1 0 1 1 1 1 0 0 1 0 0 1 0 1 1 0 1 1 1 0 0 0 1 1 0 0 0 1 1\n  0 0 0 1 1 0 1 0 1 1 1 1 0 1 1 1 0 1 1 0 0 1 0 1 1 1 0 1 1 1 0 0 0 1 0 0\n  0 1 0 0 0 1 1 1 1 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 1\n  0 1 1 1 1 0 1 0 0 0 1 1 1 0 0 1 1 1 1 1 1 1 0 0 1 0 1 0 1 0 0 0 0 0 1 0\n  0 1 1 1 0 0 1 0 1 0 0 0 1 0 1 1 1 1 1 0 1 1 1 0 0 0 1 0 1 0 0 1 1 1 1 0\n  1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0\n  0 1 1 0 1 1 1 0 0 0 1 1 0 1 1 1 1 0 1 1 0 1 0 1 0 1 0 0 1 1 0 0]] \n\n\n\n\n\n\n\n\n\n [[1 0 1 1 0 1 0 0 1 1 1 0 0 0 1 0 1 0 0 0 0 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0\n  0 0 0 1 0 0 0 0 1 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 1 1 0 0 0 1 0 1 1 0 1 1\n  1 0 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 0 0 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1\n  1 1 0 1 0 1 0 0 1 1 1 1 1 1 0 0 1 0 0 0 1 1 0 1 0 0 0 0 1 1 1 0 0 1 1 1\n  1 1 0 0 0 1 0 1 1 1 1 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 0 1 1 0 1 1 1 1\n  1 0 1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 0 1 0 1 1 0 1 1 0 0 1 1 0 1 1 1 0 1 1\n  1 1 1 1 1 0 0 1 1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 1 0 1 0 0 1 0\n  1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0\n  1 0 0 1 0 1 0 1 0 0 1 0 1 0 1 0 0 0 1 0 0 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1\n  1 1 1 1 1 0 0 1 1 1 0 0 0 0 1 0 1 1 1 0 1 0 0 1 1 0 1 0 0 1 0 1 0 1 1 1\n  0 0 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 0 0 0 0 1 0 1 1 0 1 0 0 1 1 0\n  1 1 1 1 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0\n  0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 0 0 0 0 0 1 0 0 0 1 0 1 1 0\n  0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 1 1 0 1 1 1 1 0 1 1 0 1 1 0 0]]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(X, '\\n'*10,Y )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X[0, :],X[1, :], c=Y.ravel(),s=40, cmap=plt.cm.Spectral);\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "The shape of X is: (2, 500)\nThe shape of Y is: (1, 500)\nI have m = %d training examples! 500\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "shape_X = X.shape\n",
    "shape_Y = Y.shape\n",
    "m = Y.shape[1]\n",
    "print ('The shape of X is: ' + str(shape_X))\n",
    "print ('The shape of Y is: ' + str(shape_Y))\n",
    "print ('I have m = %d training examples!',m)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\nc:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n  warnings.warn(CV_WARNING, FutureWarning)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "clf = sklearn.linear_model.LogisticRegressionCV();\n",
    "clf.fit(X.T, Y.T);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Accuracy of logistic regression: 52 % (percentage of correctly labelled datapoints)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Print accuracy\n",
    "LR_predictions = clf.predict(X.T)\n",
    "print ('Accuracy of logistic regression: %d ' % float((np.dot(Y,LR_predictions) + np.dot(1-Y,1-LR_predictions))/float(Y.size)*100) +\n",
    "       '% ' + \"(percentage of correctly labelled datapoints)\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0.5, 1.0, 'Logistic Regression')"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 502
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAYvklEQVR4nO3deZRkZZ3m8e8jOyqglCiruDAiirgUuPVxwKUb0S5scYFjC6g0Lu14pgeGxqV1mplTAjPQI6M1DipHUFkcdGi0yqFbBR0OoJQeUBBoC1Ap2aSgQASU5Td/xE07STJvZlZmxo2I/H7OiZM34r557+/GrYon3vcumapCkqSpPK7rAiRJg82gkCS1MigkSa0MCklSK4NCktTKoJAktTIoNNKSvCPJP23g716dZN95LmngJflWksO6rkODI15HoUGR5BfAEVX17Q7W/UVgbVV9bI7L2RW4Efhd89IdwGer6vi5LFfq0sZdFyCNqG2q6qEkS4HvJflRVf3zfK4gycZV9dB8LlOajENPGgpJ/irJmiR3Jjk/yQ7j5v1pkuuS3J1kRZLvJTmimXd4koub6ST5hyS3N21/kuT5SY4E3gEck+TeJN9o2v8iyWub6Y2SfCTJ9Ul+m+RHSXaeru6qWg1cDbxwXL07JPlakt8kuTHJh8bN2yLJ6UnuSnJNkmOSrB03/xdJ/jbJT4DfJdl4muXtk2R1knuS3Jbk5Ob1zZN8Ocm6JOuTXJ7kqc28i8a9f49L8rEkv2zetzOSbN3M2zVJJTksya+S3JHko7PeuRp4BoUGXpJXA58E3gZsD/wSOLuZtwQ4F/gwsC1wHfCKKRb1p8CrgH8DbAO8HVhXVacCXwFOrKonVNWfT/K7/wE4BDgA2Ap4N3DfDGp/GfB8YE3z/HHAN4ArgR2B1wD/PsmfNb/yCWBX4JnA64C/nGSxhwBvaLbhkWmW9yngU1W1FfAs4KvN64cBWwM703vf3gfcP8m6Dm8e+zU1PQH49IQ2fwI8p1n3x5M8t+090fAxKDQM3gGcVlU/rqrf0wuFlzfHAw4Arq6qrzfDMKcAt06xnAeBJwK70zs+d01V3TLDGo4APlZV11XPlVW1rqX9HUnuBy4FVgDnNa/vDTylqo6rqj9U1Q3A54CDm/lvA5ZX1V1VtbbZnolOqaqbqur+GSzvQeDZSZZU1b1Vddm417cFnl1VD1fVj6rqnknW9Q7g5Kq6oarupffeH5xk/LD131fV/VV1Jb3A2qvlfdEQMig0DHag14sAoPnAWkfvG/QOwE3j5hWwduICmnnfpfdt+DPAbUlOTbLVDGvYGbh+FjUvofft+2hgX2CT5vWnAzs0wz3rk6wHPgI8tZn/qO2ZMD3Za9Mt7z30elDXNsNLb2xe/xJwAXB2kpuTnJhkEx7rUe99M73xuOXDo4P5vma7NUIMCg2Dm+l9IAKQ5PH0vg3/GrgF2GncvIx/PlFVnVJVLwGeR+8D9D+OzZqmhpvoDd3MWPNN/STgAeAD45ZzY1VtM+7xxKo6oJn/qO2hF1CPWfSEuqZcXlX9vKoOAbYDTgDOTfL4qnqwqv6+qvagN1T3RuDQSdb1qPce2AV4CLhtFm+FhpxBoUGzSXOgdeyxMXAm8K4kL0yyGbAc+EFV/QJYCeyZ5E1N278GnjbZgpPsneSlzTfn39H7AH+4mX0bvTH4qXwe+M9JdmsOir8gybYz3Kbj6R0o3xz4IXBPc0B6i+Yg+fOT7N20/Srw4SRPSrIj8MFplt26vCR/meQpVfUIsL75nYeT7JdkzyQbAffQG4p6eJLlnwX8TZJnJHkCvff+HM+2WlwMCg2aVfQOqo49/lNVfQf4O+Br9L5xP4tmDL6q7gDeCpxIbzhqD2A18PtJlr0VvfH7u+gNoawD/lsz7wvAHs3wzXmT/O7J9D7E/4neB+sXgC1muE0rm3X+VVU9DPw5vbOgbqR3ncXn6R1YBjiO3tDZjcC36R2on2xbgF6vZZrl7Q9cneReege2D66qB+iF6bnNtlwDfA/48iSrOI3eMNX3m+U/APy7GW63RoQX3GmkNGcVrQXeUVUXdl3PXCV5P70P93/bdS1avOxRaOgl+bMk2zTDUh8BAlw2za8NpCTbJ3llc/3Cc4CjgP/TdV1a3LwyW6Pg5fSOY2wK/Ax4U3Pq6DDaFPhfwDPoHVM4m97ptVJnHHqSJLVy6EmS1Grkhp422XLr2nzr7bouQ5KGyr23rrmjqp4y2byRC4rNt96Olxz2qa7LkKSh8r0T3vDLqeY59CRJamVQSJJaGRSSpFYGhSSplUEhSWplUEiSWhkUkqRWBoUkqZVBIUlqZVBIkloZFJKkVgaFJKmVQSFJamVQSJJaGRSSpFYGhSSplUEhSWplUEiSWhkUkqRWBoUkqZVBIUlqZVBIkloZFJKkVgaFJKmVQSFJamVQSJJaGRSSpFYGhSSplUEhSWplUEiSWhkUkqRWnQZFktOS3J7kqinm75vk7iRXNI+P97tGSVrsNu54/V8EPg2c0dLm/1XVG/tTjiRpok57FFX1feDOLmuQJLUbhmMUL09yZZJvJXneZA2SHJlkdZLVD953d7/rk6SRNuhB8WPg6VW1F/A/gPMma1RVp1bV0qpausmWW/e1QEkadQMdFFV1T1Xd20yvAjZJsqTjsiRpURnooEjytCRppvehV++6bquSpMWl07OekpwF7AssSbIW+ASwCUBVfRZ4C/D+JA8B9wMHV1V1VK4kLUqdBkVVHTLN/E/TO31WktSRgR56kiR1z6CQJLUyKCRJrQwKSVIrg0KS1MqgkCS1MigkSa0MCklSK4NCktTKoJAktTIoJEmtDApJUiuDQpLUyqCQJLUyKCRJrQwKSVIrg0KS1MqgkCS1MigkSa0MCklSK4NCktTKoJAktTIoJEmtDApJUiuDQpLUyqCQJLXauOsCpDGbX7uObYBbAXbftuNqNFsHnHgSWwHXA5cfc1TX5WgeddqjSHJaktuTXDXF/CQ5JcmaJD9J8uJ+16g+uHYdu1y7ju2ATYFdgJ2vXQfXruu4MM3E8088iUNPPIkl9Pbfc4F3nnhSx1VpPnU99PRFYP+W+a8HdmseRwL/sw81qc92aX5mwmPnzirSbIx9e5u4/wyL0dFpUFTV94E7W5ocCJxRPZcB2yTZvj/VqS+aXkMmvJxJXtPg2bcJA/ffaOu6RzGdHYGbxj1f27z2KEmOTLI6yeoH77u7b8Vp7rbpugDNyZKuC1BfDHpQTPalpB7zQtWpVbW0qpZusuXWfShL82V91wVoTs6d4vXH/CfVUBv0oFjLo4eqdwJu7qgWLYTdt+URHv3BUs3j4W4q0mwcc9Qf99eYsemHOihHC2PQg+J84NDm7KeXAXdX1S1dF6X5tXZcWIz/kPm1p8gOhS8dc9Sk++9MT5EdGZ1eR5HkLGBfYEmStcAngE0AquqzwCrgAGANcB/wrm4q1UJbaygMtS8bCiOt06CoqkOmmV/AX/epHEnSJAZ96EmS1DGDQpLUyqCQJLUyKCRJrQwKSVIrg0KS1MqgkCS1MigkSa0MCklSK4NCktTKoJAktTIoJEmtDApJUiuDQpLUyqCQJLUyKCRJrQwKSVIrg0KS1MqgkCS1MigkSa0MCklSK4NCktTKoJAktTIoJEmtDApJUiuDQpLUyqCQJLUyKCRJrVqDIslWSZ41yesvmI+VJ9k/yXVJ1iQ5dpL5hyf5TZIrmscR87FeSdLMTRkUSd4GXAt8LcnVSfYeN/uLc11xko2AzwCvB/YADkmyxyRNz6mqFzaPz891vZKk2WnrUXwEeElVvRB4F/ClJG9u5mUe1r0PsKaqbqiqPwBnAwfOw3IlSfNo45Z5G1XVLQBV9cMk+wHfTLITUPOw7h2Bm8Y9Xwu8dJJ2ByV5FfAvwN9U1U0TGyQ5EjgSYLOtnjIPpUmSxrT1KH47/vhEExr70vvW/7x5WPdkvZKJAfQNYNeqegHwbeD0yRZUVadW1dKqWrrJllvPQ2mSpDFtQfF+4HHjjxtU1W+B/YH5OKi8Fth53POdgJvHN6iqdVX1++bp54CXzMN6JUmzMGVQVNWVVfVz4KtJ/jY9WwAnAx+Yh3VfDuyW5BlJNgUOBs4f3yDJ9uOeLgOumYf1SpJmYSbXUbyU3jf/S+h9uN8MvHKuK66qh4APAhfQC4CvVtXVSY5Lsqxp9qHmjKsrgQ8Bh891vZKk2Wk7mD3mQeB+YAtgc+DGqnpkPlZeVauAVRNe+/i46Q8DH56PdUmSNsxMehSX0wuKvYE/oXe9w7kLWpUkaWDMpEfxnqpa3UzfChyY5J0LWJMkaYBM26MYFxLjX/vSwpQjSRo03hRQktTKoJCkRW75yhWt8w0KSVrELjzo4mnbzORgtiRpxOy1bD1vf++ZXLpy+rYGhSQtMicffSsP7Pf1Gbd36EmSFpG9lq2fVUiAPQpJWjQuOn4LLtmz/cD1ZAwKSVoE9lq2foNCAgwKSRp5Fx50MZe++ycb/Pseo5CkETeXkAB7FJI0subakxhjUEjSiJnNNRIz4dCTJI2YT71i++kbzYI9CkkaEWM9iUvmqScxxh6FJI2I+e5JjLFHIUkjYPnKFfPekxhjUEjSEJuvM5vaOPQkSUNsoUMC7FFI0lDq3bfppL6syx6FJA2hfoUE2KOQpKHSz57EGINCkobEQp7Z1MahJ0kaAhcdv0Vn67ZHoYGw5Ykn8WYgwCPAVwCOOarTmjQL165jJ/51//0aYPdtOy1plHTVkxjTaY8iyf5JrkuyJsmxk8zfLMk5zfwfJNm1/1Vqob31xJN4C71/jAE2Ag4FXnNif8dhtWG2u3Ydu/Do/bcLwLXruixrZFx40MVdl9BdUCTZCPgM8HpgD+CQJHtMaPYe4K6qejbwD8AJ/a1S/TDWoc64B8CO3ZSjWdq8+Tlx/+3cTTkjZfnKFX25TmI6XfYo9gHWVNUNVfUH4GzgwAltDgROb6bPBV6TJGhkjPUaJu5Ud/JweGLTa5hs/7kPN9xFx2/B8pUb9mdLF0KXQbEjcNO452t57JfIP7apqoeAu4HHDHwmOTLJ6iSrH7zv7gUqVwths64L0Jx4kHNh9Pv01+l0GRSTfeGoDWhDVZ1aVUuraukmW249L8WpP1Y1B6wn7tTH7GQNpLuaA9buv/kxaD2JMV0GxVoePYy5E3DzVG2SbAxsDdzZl+rUNw82P2vCz/s6qEWz91Dzc+L+u7eDWobZXsvWD1xPYkyXQXE5sFuSZyTZFDgYOH9Cm/OBw5rptwDfrSq/rIyYs445invofcCMPX4NnOvpsUPh5t235V4evf9+Bdzp6bEzdtHxW/D2957ZdRlT6myIsaoeSvJB4AJ6Z9SdVlVXJzkOWF1V5wNfAL6UZA29nsTBXdWrhXWeoTDU7tx9W7v6G6iLW3LMVqfHoqpqFbBqwmsfHzf9APDWftclSf1w8tG3csmeX++6jGl50oIkdWD5yhU80OHV1rPhvZ4kqc9WPXJK1yXMikEhSX206pFTuOJbwzWYM1zVStIQW75yBVcM4ceuPQpJ6oNhG24ab/iiTZKGyMlH38oD+319KHsSY+xRSNICGQuJYWdQSNICGJWQAINCkubdhQddPDIhAR6jkKR5dfLRt3Lpft3/saH5ZFBI0jxZ9cgpXLHf6H2sjt4WSVIHhvUaiZnwGIUkzdEwXyMxE6MZf5LUB3stW8/b33vmyPYkxtijkKQN9Mnzzui6hL4Y7RiUpAUwCldbz4Y9CkmahVG7RmImFkccStI8GMVrJGbCoJCkGRjVayRmwqEnSZrGXsvWD90fG5pPi3fLJWkGVj1yCle8d3F/VC7urZekKSyWayRmwqEnSZrEf9/kqq5LGBhGpSSNM3aNxKUru65kcNijkKRxXnTjmq5LGDj2KCSJfz0mYU/isexRSBIek2jTSY8iyZOBc4BdgV8Ab6uquyZp9zDw0+bpr6pqWb9qlLQ42JOYXlc9imOB71TVbsB3mueTub+qXtg8DAlJ8+rCgy7m7e89s+syBl5XQXEgcHozfTrwpo7qkLRI7bVsPZe+e/Hdt2lDdHUw+6lVdQtAVd2SZLsp2m2eZDXwEHB8VZ03WaMkRwJHAmy21VMWol5JI+TCgy42JGZhwYIiybeBp00y66OzWMwuVXVzkmcC303y06q6fmKjqjoVOBXgidvvVhtUsKRFYbHeAXYuFiwoquq1U81LcluS7ZvexPbA7VMs4+bm5w1JLgJeBDwmKCRpJi486GJDYgN0dYzifOCwZvow4B8nNkjypCSbNdNLgFcCP+tbhZJGxl7L1rN85QqHmzZQV0FxPPC6JD8HXtc8J8nSJJ9v2jwXWJ3kSuBCescoDApJs+Y1EnPTycHsqloHvGaS11cDRzTTlwB79rk0SSPEayTmh1dmSxpZnzzvjK5LGAne60nSyPFvScwv30VJI8VrJOafQ0+SRoZXWy8MexSSRoI9iYVjUEgaehcdvwWX7GlILBSHniQNtV5InNR1GSPNHoWkoTR2ZtMlXiOx4OxRSBpKXiPRP/YoJA2d5StXeI1EH9mjkDRUlq9c0XUJi45BIWloGBLdsO8maeCdfPStPLDf17suY9GyRyFp4BkS3bJHIWlgeY3EYDAoJA2kCw+62KutB4RBIWngeEuOwWJQSBooqx45hUv29KNpkLg3JA2MXk/Cj6VB4x6RNBCWr1zhfZsGlEEhqVNeIzH4vI5CUqcMicFnj0JSJ7xGYnjYo5DUifuOOaHrEjRD9igk9dVYT8LbhA8P95SkvvEaieHkHpPUFycffStX7OdHzjByr0lacMtXruABr5EYWp0czE7y1iRXJ3kkydKWdvsnuS7JmiTH9rNGSfPj5KNv7boEzVFXZz1dBbwZ+P5UDZJsBHwGeD2wB3BIkj36U56k+bDqkVO8TmIEdDL0VFXXACRpa7YPsKaqbmjang0cCPxswQuUNCee2TRaBnkv7gjcNO75WuClkzVMciRwZPP099874Q1XLXBtXVoC3NF1EQvI7RtuS4A7MrqXSIzy/nv6VDMWLCiSfBt42iSzPlpV/ziTRUzyWk3WsKpOBU5t1ru6qqY87jHs3L7h5vYNt1HfvqksWFBU1WvnuIi1wM7jnu8E3DzHZUqSZmmQb+FxObBbkmck2RQ4GDi/45okadHp6vTYv0iyFng5sDLJBc3rOyRZBVBVDwEfBC4ArgG+WlVXz2Dxpy5Q2YPC7Rtubt9wG/Xtm1SqJh32lyQJGOyhJ0nSADAoJEmthj4oRv12IEmenOSfk/y8+fmkKdo9nOSK5jHwB/2n2x9JNktyTjP/B0l27X+VG24G23d4kt+M22dHdFHnhkpyWpLbk0x6zVJ6Tmm2/ydJXtzvGudiBtu3b5K7x+2/j/e7xr6qqqF+AM8FngNcBCydos1GwPXAM4FNgSuBPbqufYbbdyJwbDN9LHDCFO3u7brWWWzTtPsD+ADw2Wb6YOCcruue5+07HPh017XOYRtfBbwYuGqK+QcA36J3PdTLgB90XfM8b9++wDe7rrNfj6HvUVTVNVV13TTN/ng7kKr6AzB2O5BhcCBwejN9OvCmDmuZLzPZH+O3+1zgNZnmni8DZJj/vc1IVX0fuLOlyYHAGdVzGbBNku37U93czWD7FpWhD4oZmux2IDt2VMtsPbWqbgFofm43RbvNk6xOclmSQQ+TmeyPP7ap3qnSdwPb9qW6uZvpv7eDmmGZc5PsPMn8YTbM/+dm6uVJrkzyrSTP67qYhTTI93r6o37eDqQLbds3i8XsUlU3J3km8N0kP62q6+enwnk3k/0x0PtsGjOp/RvAWVX1+yTvo9d7evWCV9Y/w7z/ZuLHwNOr6t4kBwDnAbt1XNOCGYqgqBG/HUjb9iW5Lcn2VXVL03W/fYpl3Nz8vCHJRcCL6I2TD6KZ7I+xNmuTbAxszfAMBUy7fVW1btzTzwGjdhu9gf4/N1dVdc+46VVJViRZUlUjecPAxTL0NMy3AzkfOKyZPgx4TA8qyZOSbNZMLwFeyWDfjn0m+2P8dr8F+G41RxGHwLTbN2G8fhm9uw+MkvOBQ5uzn14G3D02hDoKkjxt7JhZkn3ofZaua/+tIdb10fS5PoC/oPft5ffAbcAFzes7AKvGtTsA+Bd637I/2nXds9i+bYHvAD9vfj65eX0p8Plm+hXAT+mdXfNT4D1d1z2D7XrM/gCOA5Y105sD/xtYA/wQeGbXNc/z9n0SuLrZZxcCu3dd8yy37yzgFuDB5v/fe4D3Ae9r5ofeHx67vvk3OekZiYP6mMH2fXDc/rsMeEXXNS/kw1t4SJJaLZahJ0nSBjIoJEmtDApJUiuDQpLUyqCQJLUyKKQ+SvJ/k6xP8s2ua5FmyqCQ+uu/Au/sughpNgwKaQEk2bu54d/mSR7f/M2U51fVd4Dfdl2fNBtDca8nadhU1eXNH5D6L8AWwJeratI/giMNOoNCWjjH0bvv0wPAhzquRdpgDj1JC+fJwBOAJ9K7d5U0lAwKaeGcCvwd8BVG7zbiWkQcepIWQJJDgYeq6swkGwGXJHk18PfA7sATkqyld6ffC7qsVZqOd4+VJLVy6EmS1MqgkCS1MigkSa0MCklSK4NCktTKoJAktTIoJEmt/j80Chp7rZ+J2AAAAABJRU5ErkJggg==\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_decision_boundary(model, X, y):\n",
    "    # Set min and max values and give it some padding\n",
    "    x_min, x_max = X[0, :].min() - 1, X[0, :].max() + 1\n",
    "    y_min, y_max = X[1, :].min() - 1, X[1, :].max() + 1\n",
    "    h = 0.01\n",
    "    # Generate a grid of points with distance h between them\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    # Predict the function value for the whole grid\n",
    "    Z = model(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    # Plot the contour and training examples\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n",
    "    plt.ylabel('x2')\n",
    "    plt.xlabel('x1')\n",
    "    plt.scatter(X[0, :], X[1, :], c=y.ravel(), cmap=plt.cm.Spectral)\n",
    "# Plot the decision boundary\n",
    "# Plot the decision boundary for logistic regression\n",
    "plot_decision_boundary(lambda x: clf.predict(x), X, Y)\n",
    "plt.title(\"Logistic Regression\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "outputs": [],
   "source": [
    "def layer_sizes(X, Y):\n",
    "    n_x = X.shape[0] # size of input layer\n",
    "    n_h = 2 #size of hidden layer\n",
    "    n_y = Y.shape[0] # size of output layer\n",
    "    return n_x, n_h, n_y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "The size of the input layer is: n_x = 2\nThe size of the hidden layer is: n_h = 2\nThe size of the output layer is: n_y = 1\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "(n_x, n_h, n_y) = layer_sizes(X, Y)\n",
    "print(\"The size of the input layer is: n_x = \" + str(n_x))\n",
    "print(\"The size of the hidden layer is: n_h = \" + str(n_h))\n",
    "print(\"The size of the output layer is: n_y = \" + str(n_y))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    n_x -- size of the input layer\n",
    "    n_h -- size of the hidden layer\n",
    "    n_y -- size of the output layer\n",
    "    \n",
    "    Returns:\n",
    "    params -- python dictionary containing your parameters:\n",
    "                    W1 -- weight matrix of shape (n_h, n_x)\n",
    "                    b1 -- bias vector of shape (n_h, 1)\n",
    "                    W2 -- weight matrix of shape (n_y, n_h)\n",
    "                    b2 -- bias vector of shape (n_y, 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(2)\n",
    "    W1 =  np.random.randn(n_h, n_x) * 0.01\n",
    "    b1 = np.zeros((n_h, 1))\n",
    "    W2 =  np.random.randn(n_y,n_h) * 0.01\n",
    "    b2 = np.zeros((n_y,1))\n",
    "    \n",
    "    assert (W1.shape == (n_h, n_x))\n",
    "    assert (b1.shape == (n_h, 1))\n",
    "    assert (W2.shape == (n_y, n_h))\n",
    "    assert (b2.shape == (n_y, 1))\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "W1 = [[-0.00416758 -0.00056267]\n [-0.02136196  0.01640271]]\nb1 = [[0.]\n [0.]]\nW2 = [[-0.01793436 -0.00841747]]\nb2 = [[0.]]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "\n",
    "parameters = initialize_parameters(n_x, n_h, n_y)\n",
    "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "print(\"b2 = \" + str(parameters[\"b2\"]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "outputs": [],
   "source": [
    "\n",
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    X -- input data of size (n_x, m)\n",
    "    parameters -- python dictionary containing your parameters (output of initialization function)\n",
    "    \n",
    "    Returns:\n",
    "    A2 -- The sigmoid output of the second activation\n",
    "    cache -- a dictionary containing \"Z1\", \"A1\", \"Z2\" and \"A2\"\n",
    "    \"\"\"\n",
    "    # Retrieve each parameter from the dictionary \"parameters\"\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    \n",
    "    # Implement Forward Propagation to calculate A2 (probabilities)\n",
    "    Z1 = np.dot(W1,X)+b1\n",
    "    A1 = np.tanh(Z1)\n",
    "    Z2 = np.dot(W2,A1)+b2\n",
    "    A2 = sigmoid(Z2)\n",
    "    \n",
    "    assert(A2.shape == (1, X.shape[1]))\n",
    "    \n",
    "    cache = {\"Z1\": Z1,\n",
    "             \"A1\": A1,\n",
    "             \"Z2\": Z2,\n",
    "             \"A2\": A2}\n",
    "    \n",
    "    return A2, cache"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "-0.002282426127198799 -0.0022821984437736264 6.073401668250271e-05 0.5000151835040849\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "A2, cache = forward_propagation(X, parameters)\n",
    "\n",
    "# Note: we use the mean here just to make sure that your output matches ours. \n",
    "print(np.mean(cache['Z1']) ,np.mean(cache['A1']),np.mean(cache['Z2']),np.mean(cache['A2']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "outputs": [],
   "source": [
    "def compute_cost(A2, Y, parameters):\n",
    "    \"\"\"\n",
    "    Computes the cross-entropy cost given in equation (13)\n",
    "    \n",
    "    Arguments:\n",
    "    A2 -- The sigmoid output of the second activation, of shape (1, number of examples)\n",
    "    Y -- \"true\" labels vector of shape (1, number of examples)\n",
    "    parameters -- python dictionary containing your parameters W1, b1, W2 and b2\n",
    "    [Note that the parameters argument is not used in this function, \n",
    "    but the auto-grader currently expects this parameter.\n",
    "    Future version of this notebook will fix both the notebook \n",
    "    and the auto-grader so that `parameters` is not needed.\n",
    "    For now, please include `parameters` in the function signature,\n",
    "    and also when invoking this function.]\n",
    "    \n",
    "    Returns:\n",
    "    cost -- cross-entropy cost given equation (13)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    m = Y.shape[1] # number of example\n",
    "\n",
    "    # Compute the cross-entropy cost\n",
    "    logprobs = np.multiply(np.log(A2),Y)+np.multiply(np.log(1-A2),(1-Y))\n",
    "    cost =(-1/m)* np.sum(logprobs)\n",
    "    cost = float(np.squeeze(cost))  # makes sure cost is the dimension we expect. \n",
    "                                    # E.g., turns [[17]] into 17 \n",
    "    assert(isinstance(cost, float))\n",
    "    \n",
    "    return cost"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "cost = 0.6931471951978843\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(\"cost = \" + str(compute_cost(A2, Y, parameters)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "outputs": [],
   "source": [
    "def backward_propagation(parameters, cache, X, Y):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation using the instructions above.\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing our parameters \n",
    "    cache -- a dictionary containing \"Z1\", \"A1\", \"Z2\" and \"A2\".\n",
    "    X -- input data of shape (2, number of examples)\n",
    "    Y -- \"true\" labels vector of shape (1, number of examples)\n",
    "    \n",
    "    Returns:\n",
    "    grads -- python dictionary containing your gradients with respect to different parameters\n",
    "    \"\"\"\n",
    "    m = X.shape[1]\n",
    "    \n",
    "    # First, retrieve W1 and W2 from the dictionary \"parameters\".\n",
    "    ### START CODE HERE ### (≈ 2 lines of code)\n",
    "    W1 =  parameters['W1']\n",
    "    W2 =  parameters['W2']\n",
    "    ### END CODE HERE ###\n",
    "        \n",
    "    # Retrieve also A1 and A2 from dictionary \"cache\".\n",
    "    ### START CODE HERE ### (≈ 2 lines of code)\n",
    "    A1 = cache['A1']\n",
    "    A2 = cache['A2']\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Backward propagation: calculate dW1, db1, dW2, db2. \n",
    "    ### START CODE HERE ### (≈ 6 lines of code, corresponding to 6 equations on slide above)\n",
    "    dZ2 = A2-Y\n",
    "    dW2 = (1/m)*np.dot(dZ2,A1.T)\n",
    "    db2 = (1/m)*np.sum(dZ2,axis=1,keepdims=True)\n",
    "    dZ1 = np.multiply(np.dot(W2.T,dZ2),(1 - np.power(A1, 2)))\n",
    "    dW1 = (1/m)*np.dot(dZ1,X.T)\n",
    "    db1 = (1/m)*np.sum(dZ1,axis=1,keepdims=True)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    grads = {\"dW1\": dW1,\n",
    "             \"db1\": db1,\n",
    "             \"dW2\": dW2,\n",
    "             \"db2\": db2}\n",
    "    \n",
    "    return grads\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "dW1 = [[1.25123023e-04 2.51145937e-04]\n [5.82595648e-05 1.17574280e-04]]\ndb1 = [[0.00039429]\n [0.00018429]]\ndW2 = [[ 3.69531079e-05 -8.08383015e-05]]\ndb2 = [[-0.02198482]]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "\n",
    "\n",
    "grads = backward_propagation(parameters, cache, X, Y)\n",
    "print (\"dW1 = \"+ str(grads[\"dW1\"]))\n",
    "print (\"db1 = \"+ str(grads[\"db1\"]))\n",
    "print (\"dW2 = \"+ str(grads[\"dW2\"]))\n",
    "print (\"db2 = \"+ str(grads[\"db2\"]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate = 1.2):\n",
    "    \"\"\"\n",
    "    Updates parameters using the gradient descent update rule given above\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing your parameters \n",
    "    grads -- python dictionary containing your gradients \n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your updated parameters \n",
    "    \"\"\"\n",
    "    # Retrieve each parameter from the dictionary \"parameters\"\n",
    "    ### START CODE HERE ### (≈ 4 lines of code)\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Retrieve each gradient from the dictionary \"grads\"\n",
    "    ### START CODE HERE ### (≈ 4 lines of code)\n",
    "    dW1 = grads['dW1']\n",
    "    db1 = grads['db1']\n",
    "    dW2 = grads['dW2']\n",
    "    db2 = grads['db2']\n",
    "    ## END CODE HERE ###\n",
    "    \n",
    "    # Update rule for each parameter\n",
    "    ### START CODE HERE ### (≈ 4 lines of code)\n",
    "    W1 = W1-learning_rate*dW1\n",
    "    b1 = b1-learning_rate*db1\n",
    "    W2 = W2-learning_rate*dW2\n",
    "    b2 = b2-learning_rate*db2\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "W1 = [[-0.00431773 -0.00086404]\n [-0.02143187  0.01626162]]\nb1 = [[-0.00047315]\n [-0.00022115]]\nW2 = [[-0.0179787  -0.00832047]]\nb2 = [[0.02638178]]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "parameters = update_parameters(parameters, grads)\n",
    "\n",
    "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "print(\"b2 = \" + str(parameters[\"b2\"]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "outputs": [],
   "source": [
    "def nn_model(X, Y, n_h, num_iterations = 10000, print_cost=False):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    X -- dataset of shape (2, number of examples)\n",
    "    Y -- labels of shape (1, number of examples)\n",
    "    n_h -- size of the hidden layer\n",
    "    num_iterations -- Number of iterations in gradient descent loop\n",
    "    print_cost -- if True, print the cost every 1000 iterations\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(3)\n",
    "    n_x = layer_sizes(X, Y)[0]\n",
    "    n_y = layer_sizes(X, Y)[2]\n",
    "    \n",
    "    # Initialize parameters\n",
    "    ### START CODE HERE ### (≈ 1 line of code)\n",
    "    parameters =initialize_parameters(n_x, n_h, n_y)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Loop (gradient descent)\n",
    "\n",
    "    for i in range(0, num_iterations):\n",
    "         \n",
    "        ### START CODE HERE ### (≈ 4 lines of code)\n",
    "        # Forward propagation. Inputs: \"X, parameters\". Outputs: \"A2, cache\".\n",
    "        A2, cache =forward_propagation(X, parameters)\n",
    "        \n",
    "        # Cost function. Inputs: \"A2, Y, parameters\". Outputs: \"cost\".\n",
    "        cost = compute_cost(A2, Y, parameters)\n",
    " \n",
    "        # Backpropagation. Inputs: \"parameters, cache, X, Y\". Outputs: \"grads\".\n",
    "        grads= backward_propagation(parameters, cache, X, Y)\n",
    " \n",
    "        # Gradient descent parameter update. Inputs: \"parameters, grads\". Outputs: \"parameters\".\n",
    "        parameters = update_parameters(parameters, grads, learning_rate = 1.2)\n",
    "        \n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        # Print the cost every 1000 iterations\n",
    "        if print_cost and i % 1000 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "\n",
    "    return parameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Cost after iteration 0: 0.693152\n",
      "Cost after iteration 1000: 0.008527\n",
      "Cost after iteration 2000: 0.001563\n",
      "Cost after iteration 3000: 0.000855\n",
      "Cost after iteration 4000: 0.000588\n",
      "Cost after iteration 5000: 0.000448\n",
      "Cost after iteration 6000: 0.000362\n",
      "Cost after iteration 7000: 0.000303\n",
      "Cost after iteration 8000: 0.000261\n",
      "Cost after iteration 9000: 0.000229\n",
      "W1 = [[-1.1477977  -1.07314565]\n [-4.50301144  3.96568836]\n [-3.70799829  4.34322631]\n [-1.2261721  -1.14577521]]\nb1 = [[-0.7010266 ]\n [-1.88519909]\n [ 1.71753311]\n [-0.62052676]]\nW2 = [[-2.34275138  8.68876762 -8.66386184 -2.4762464 ]]\nb2 = [[4.13836385]]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "parameters = nn_model(X, Y, 4, num_iterations=10000, print_cost=True)\n",
    "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "print(\"b2 = \" + str(parameters[\"b2\"]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "outputs": [],
   "source": [
    "def predict(parameters, X):\n",
    "    \"\"\"\n",
    "    Using the learned parameters, predicts a class for each example in X\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing your parameters \n",
    "    X -- input data of size (n_x, m)\n",
    "    \n",
    "    Returns\n",
    "    predictions -- vector of predictions of our model (red: 0 / blue: 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Computes probabilities using forward propagation, and classifies to 0/1 using 0.5 as the threshold.\n",
    "    ### START CODE HERE ### (≈ 2 lines of code)\n",
    "    A2, cache = forward_propagation(X, parameters)\n",
    "    predictions = (A2>0.5)\n",
    "            \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "predictions mean = 0.522\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "predictions = predict(parameters, X)\n",
    "print(\"predictions mean = \" + str(np.mean(predictions)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Accuracy: 100%\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Print accuracy\n",
    "predictions = predict(parameters, X)\n",
    "print ('Accuracy: %d' % float((np.dot(Y,predictions.T) + np.dot(1-Y,1-predictions.T))/float(Y.size)*100) + '%')\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Cost after iteration 0: 0.693152\n",
      "Cost after iteration 1000: 0.008527\n",
      "Cost after iteration 2000: 0.001563\n",
      "Cost after iteration 3000: 0.000855\n",
      "Cost after iteration 4000: 0.000588\n",
      "Cost after iteration 5000: 0.000448\n",
      "Cost after iteration 6000: 0.000362\n",
      "Cost after iteration 7000: 0.000303\n",
      "Cost after iteration 8000: 0.000261\n",
      "Cost after iteration 9000: 0.000229\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "Text(0.5, 1.0, 'Decision Boundary for hidden layer size 4')"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 520
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build a model with a n_h-dimensional hidden layer\n",
    "parameters = nn_model(X, Y, n_h = 4, num_iterations = 10000, print_cost=True)\n",
    "\n",
    "# Plot the decision boundary\n",
    "plot_decision_boundary(lambda x: predict(parameters, x.T), X, Y)\n",
    "plt.title(\"Decision Boundary for hidden layer size \" + str(4))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}